# Three-Layer AI System Integration Guide\n\nIntegrating your Git-trained model with Claude, n8n, and local LLMs\n\n---\n\n## System Overview\n\n```\n┌──────────────────────────────────────────────────────────────┐\n│ LAYER 1: STRATEGIC VISION (Claude via Perplexity Pro)       │\n├──────────────────────────────────────────────────────────────┤\n│ • Architecture decisions                                     │\n│ • Feature design & review                                    │\n│ • Codebase-aware suggestions                               │\n│ • Integration with embeddings from git-model               │\n└──────────────────────────────────────────────────────────────┘\n                          ▲\n                          │\n                     (API calls)\n                          │\n┌──────────────────────────────────────────────────────────────┐\n│ LAYER 2: ORCHESTRATION (n8n running on Ryzen PC)           │\n├──────────────────────────────────────────────────────────────┤\n│ • Git hook triggers                                         │\n│ • Task routing (simple → local, complex → Claude)         │\n│ • Context retrieval from Qdrant embeddings                │\n│ • Model selection & coordination                           │\n│ • Test execution & validation                             │\n└──────────────────────────────────────────────────────────────┘\n                          ▲\n                          │\n                   (Orchestration)\n                          │\n┌──────────────────────────────────────────────────────────────┐\n│ LAYER 3: EXECUTION (Local Models on Ryzen PC)              │\n├──────────────────────────────────────────────────────────────┤\n│ • Llama 2 70B (main execution)                             │\n│ • Code Llama 34B (Rust-specific)                           │\n│ • Your-trained git-model (codebase understanding)         │\n│ • Test execution & validation                             │\n│ • Commit management                                        │\n└──────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## Layer 1: Claude + Perplexity Pro Integration\n\n### Setup\n\n1. **Get Perplexity Pro API Key**\n   ```\n   https://www.perplexity.ai/api\n   Save to: ~/.env\n   PERPLEXITY_API_KEY=pplx-xxxxx...\n   ```\n\n2. **Extract relevant context from embeddings**\n   ```python\n   import json\n   import os\n   from pathlib import Path\n\n   # Load trained embeddings\n   embeddings_file = Path.home() / \"projects\" / \"the-block\" / \".perplexity\" / \"git-scrape-scripting\" / \"embeddings\" / \"commits.jsonl\"\n   \n   commits = []\n   with open(embeddings_file, 'r') as f:\n       for line in f:\n           commits.append(json.loads(line))\n   \n   # Group by theme\n   themes = {}\n       for commit in commits:\n           theme = extract_theme(commit['metadata']['message_subject'])\n           if theme not in themes:\n               themes[theme] = []\n           themes[theme].append(commit['metadata'])\n   \n   return themes\n   ```\n\n### Usage Example\n\n**Prompt to Claude** (via Perplexity):\n\n```\nYou are a co-founder helping develop The Block L1 blockchain.\n\nContext from codebase evolution:\n\nEnergy Market Development (12 commits):\n- Dispute resolution RPC implementation\n- Settlement validation logic\n- Provider/buyer lifecycle management\n\nGovernance Integration (8 commits):\n- Treasury model patterns\n- Voting lifecycle\n- Execution phase handling\n\nRecent architectural decisions:\n- Modular crate structure (40+ crates)\n- Deterministic replay testing\n- Energy market as core system\n\nQuestion: Given this codebase progression, what is the next \nmost valuable subsystem to build? Consider:\n1. System dependencies (what else needs this)\n2. Unimplemented patterns (where is code incomplete)\n3. Risk factors (what could break determinism)\n4. Integration points (how does it connect to energy market)\n\nProvide:\n1. High-level architecture\n2. Implementation phases\n3. Testing strategy\n```\n\n**Claude returns**:\n```json\n{\n  \"recommended_feature\": \"Bridge Layer for Cross-Chain Settlement\",\n  \"rationale\": \"...\",\n  \"architecture\": {\n    \"phase_1\": \"Core bridge ledger state\",\n    \"phase_2\": \"Settlement validation\",\n    \"phase_3\": \"Dispute handling\"\n  },\n  \"depends_on\": [\"energy_market\", \"governance\"],\n  \"risk_factors\": [\"Determinism in timestamp handling\"],\n  \"testing_strategy\": \"...\"\n}\n```\n\n### Integration with n8n\n\n```javascript\n// n8n HTTP Request Node\nconst response = await fetch('https://api.perplexity.ai/chat/completions', {\n  method: 'POST',\n  headers: {\n    'Authorization': `Bearer ${env['PERPLEXITY_API_KEY']}`,\n    'Content-Type': 'application/json'\n  },\n  body: JSON.stringify({\n    model: 'pplx-api-online',  // Or claude-3 if available\n    messages: [\n      {\n        role: 'system',\n        content: `You are co-founder for The Block L1 blockchain.\n\nCodebase context from git-model analysis:\n${codebaseContext}`\n      },\n      {\n        role: 'user',\n        content: `Task: ${task}\n\nProvide architecture, phases, and testing strategy.`\n      }\n    ],\n    temperature: 0.7,\n    max_tokens: 2000\n  })\n});\n\nreturn response.json();\n```\n\n---\n\n## Layer 2: n8n Orchestration Setup\n\n### Installation\n\n```bash\n# On Ryzen PC (Linux)\nsudo apt install docker docker-compose\n\n# Start n8n\ndocker run -it -p 5678:5678 n8nio/n8n:latest\n\n# Or with docker-compose\ncat > docker-compose.yml << 'EOF'\nversion: '3.8'\nservices:\n  n8n:\n    image: n8nio/n8n:latest\n    ports:\n      - \"5678:5678\"\n    environment:\n      - N8N_BASIC_AUTH_ACTIVE=true\n      - N8N_BASIC_AUTH_USER=admin\n      - N8N_BASIC_AUTH_PASSWORD=changeme\n    volumes:\n      - ~/.n8n:/home/node/.n8n\nEOF\n\ndocker-compose up -d\n```\n\nAccess at `http://localhost:5678`\n\n### Workflow 1: Task Analysis & Routing\n\n**Trigger**: User input via CLI or webhook\n\n```javascript\n// Input processing\nconst task = input.task;  // \"Add energy market dispute RPC\"\nconst complexity = analyzeComplexity(task);\n// Returns: {score: 8/10, category: \"integration\"}\n\nreturn {\n  task,\n  complexity,\n  should_use_claude: complexity.score > 6\n};\n```\n\n**Routing Decision**:\n```javascript\nif (input.complexity.score > 6) {\n  // Route to Claude (strategic)\n  return {\n    executor: 'claude',\n    flow: 'strategic_design'\n  };\n} else {\n  // Route to local model (tactical)\n  return {\n    executor: 'llama',\n    flow: 'direct_execution'\n  };\n}\n```\n\n### Workflow 2: Strategic Flow (Claude)\n\n```\n[Task Input]\n   ↓\n[Retrieve Similar Commits]\n   ↓ (Qdrant similarity search)\n[Get Embeddings Context]\n   ↓\n[Call Claude with Architecture]\n   ↓\n[Break into Subtasks]\n   ↓\n[Route to Llama for Implementation]\n   ↓\n[Validate & Test]\n   ↓\n[Commit if Passes]\n```\n\n**Implementation**:\n\n```javascript\n// Retrieve context from Qdrant\nconst queryVector = await embedQuery(task);\nconst similarCommits = await fetch('http://localhost:6333/search', {\n  method: 'POST',\n  body: JSON.stringify({\n    collection_name: 'the-block-commits',\n    query_vector: queryVector,\n    limit: 10\n  })\n}).then(r => r.json());\n\nconst context = similarCommits.result\n  .map(c => `${c.payload.commit_hash.slice(0,8)}: ${c.payload.message}`)\n  .join('\\n');\n\n// Call Claude\nconst architecture = await callClaude({\n  task: input.task,\n  codebase_context: context\n});\n\nreturn {\n  architecture,\n  subtasks: architecture.phases.map(p => ({\n    name: p,\n    executor: 'llama',\n    context: context\n  }))\n};\n```\n\n### Workflow 3: Tactical Execution (Llama)\n\n```\n[Subtask Input + Context]\n   ↓\n[Generate Code with git-model Context]\n   ↓\n[Format & Stage]\n   ↓\n[Run cargo fmt/clippy]\n   ↓\n[Run Tests]\n   ↓\n   ├─ [PASS] → Commit\n   └─ [FAIL] → Retry or Escalate to Claude\n```\n\n**Implementation**:\n\n```javascript\n// Load trained model\nconst modelPath = '/home/user/projects/the-block/.perplexity/git-scrape-scripting/models/the-block-git-model-final';\n\n// Llama execution via n8n Python node\nconst codeGeneration = await ollama.generate({\n  model: 'llama2:70b-q4_K_M',\n  prompt: `Context from The Block codebase:\n${input.context}\n\nTask: ${input.task}\n\nGenerate Rust code:`,\n  temperature: 0.7,\n  num_predict: 1024\n});\n\nreturn codeGeneration.response;\n```\n\n### Workflow 4: Testing & Validation\n\n```javascript\n// Stage code\nawait git.checkout('-b', `feature/${taskId}`);\nawait fs.writeFile(filePath, generatedCode);\n\n// Format\nawait shell.exec('cargo fmt');\nawait shell.exec('cargo clippy --all --all-targets');\n\n// Test\nconst testResult = await shell.exec('cargo test --all --lib');\nconst replayResult = await shell.exec('cargo test --test replay');\n\nreturn {\n  success: testResult.exitCode === 0 && replayResult.exitCode === 0,\n  test_output: testResult.stdout,\n  errors: testResult.stderr\n};\n```\n\n---\n\n## Layer 3: Local Model Execution\n\n### Setup Ollama on Ryzen PC\n\n```bash\n# Install Ollama\nwget https://ollama.ai/install.sh\nsh install.sh\n\n# Download models\nollama pull llama2:70b-q4_K_M      # Main executor\nollama pull codellama:34b-q5_K_M   # Code specialist\nollama serve &\n\n# Verify running\ncurl http://localhost:11434/api/tags\n```\n\n### Load Your Trained Model\n\n```bash\n# Copy model to Ollama directory\ncp -r ~/.perplexity/git-scrape-scripting/models/the-block-git-model-final \\\n  ~/.ollama/models/manifests/your-trained-model\n\n# Or load via transformers\npython3 << 'EOF'\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n\nmodel_path = \"/home/user/projects/the-block/.perplexity/git-scrape-scripting/models/the-block-git-model-final\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n\n# Use in pipeline\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_length=512,\n    device_map=\"auto\"\n)\n\noutput = pipe(\"<COMMIT> a1b2c3d <MESSAGE> Add energy market\")\nprint(output[0]['generated_text'])\nEOF\n```\n\n### Context-Aware Code Generation\n\n```python\nimport json\nfrom pathlib import Path\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n\n# Load git-model\nmodel_path = \"/path/to/the-block-git-model-final\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n\n# Load embeddings for context\nembeddings_file = Path(\"/path/to/embeddings/commits.jsonl\")\ncommits = [json.loads(line) for line in open(embeddings_file)]\n\n# Get similar commits\nquery = \"energy market dispute RPC\"\nsimilar = find_similar(commits, query, top_k=3)\n\n# Build context prompt\ncontext_prompt = f\"\"\"\nCodebase examples:\n{format_commits_as_context(similar)}\n\nTask: {query}\n\nGenerate Rust code following patterns above:\n\"\"\"\n\n# Generate\npipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\noutput = pipe(context_prompt, max_length=1024)[0]['generated_text']\n\nprint(output)\n```\n\n---\n\n## Complete Example: Adding Energy Market Feature\n\n### Step 1: User Input\n\n```bash\nthe-block-ai assign-task \"implement energy market dispute resolution RPC like governance treasury model\"\n```\n\n### Step 2: n8n Task Analysis\n\n```\nComplexity Score: 8/10 (Integration with existing systems)\n→ Route to Claude (Strategic)\n```\n\n### Step 3: Claude Designs Architecture\n\n**Input**:\n```\nContext: Last 5 energy-market commits show:\n- Dispute struct with status tracking\n- Provider/buyer relationships\n- Voting mechanism\n\nLast 3 governance commits show:\n- Treasury RPC patterns\n- Resolution phase lifecycle\n```\n\n**Output**:\n```json\n{\n  \"design\": {\n    \"new_rpcs\": [\n      \"propose_energy_dispute(dispute_id, reason)\",\n      \"vote_on_dispute(dispute_id, vote)\",\n      \"resolve_dispute(dispute_id, outcome)\"\n    ],\n    \"new_state\": \"energy_disputes: HashMap<DisputeId, Dispute>\",\n    \"validation_rules\": [\n      \"Only participants can vote\",\n      \"Voting closes after N blocks\",\n      \"Resolution must match outcome\"\n    ]\n  },\n  \"implementation_phases\": [\n    \"Add Dispute struct and ledger\",\n    \"Implement RPC handlers\",\n    \"Add state validation\",\n    \"Write tests\"\n  ]\n}\n```\n\n### Step 4: n8n Breaks into Subtasks\n\n```\nTask A: Add Dispute struct to energy_market/src/ledger.rs\nTask B: Implement RPC in energy_market/src/rpc.rs\nTask C: Add validation in energy_market/src/validation.rs\nTask D: Write 5 integration tests\n```\n\n### Step 5: Llama Executes Task A\n\n**Prompt**:\n```\nContext from The Block:\n- Last energy market changes: (from embeddings)\n- Governance dispute patterns: (from embeddings)\n- Your trained model understanding: (git-model inference)\n\nTask: Add Dispute struct to ledger with fields:\n- dispute_id (hash)\n- provider_id (address)\n- buyer_id (address)\n- status (Draft/Voting/Resolved)\n- votes: Vec<Vote>\n\nFollow patterns from governance treasury model.\n```\n\n**Output**:\n```rust\npub struct Dispute {\n    pub dispute_id: Hash,\n    pub provider_id: Address,\n    pub buyer_id: Address,\n    pub status: DisputeStatus,\n    pub created_block: BlockHeight,\n    pub votes: Vec<Vote>,\n    pub resolution: Option<DisputeResolution>,\n}\n\nimpl Dispute {\n    pub fn new(provider_id: Address, buyer_id: Address, reason: String) -> Self {\n        Self {\n            dispute_id: Hash::default(),\n            provider_id,\n            buyer_id,\n            status: DisputeStatus::Draft,\n            created_block: 0,\n            votes: vec![],\n            resolution: None,\n        }\n    }\n    \n    pub fn is_expired(&self, current_block: BlockHeight) -> bool {\n        current_block - self.created_block > DISPUTE_VOTING_PERIOD\n    }\n}\n```\n\n### Step 6: Testing & Validation\n\n```\n✓ cargo fmt passed\n✓ cargo clippy passed\n✓ cargo test energy_market passed\n✓ cargo test --test replay passed (determinism check)\n\n→ COMMIT to feature/energy-disputes-A\n→ Move to Task B\n```\n\n### Step 7: Iterative Development\n\nRepeat for Tasks B, C, D until complete feature is implemented.\n\nIf any task fails 3x → Escalate to Claude for help.\n\n---\n\n## Monitoring & Debugging\n\n### Check Layer Status\n\n```bash\n# Claude API\ncurl -H \"Authorization: Bearer $PERPLEXITY_API_KEY\" \\\n  https://api.perplexity.ai/chat/completions -X POST -d '{\"messages\": [{\"role\": \"user\", \"content\": \"ping\"}]}'\n\n# n8n\ncurl http://localhost:5678/api/v1/workflows\n\n# Ollama\ncurl http://localhost:11434/api/tags\n\n# Qdrant\ncurl http://localhost:6333/health\n```\n\n### View Logs\n\n```bash\n# n8n logs\ndocker logs n8n_n8n_1\n\n# Ollama logs\njournalctl -u ollama -f\n\n# Model training progress\ntail -f pipeline.log\n```\n\n---\n\n## Performance Metrics\n\n```\nLayer 1 (Claude):\n  - Response time: 5-30 seconds\n  - Cost: ~$0.01-0.10 per architecture decision\n  - Quality: Excellent (general reasoning)\n\nLayer 2 (n8n):\n  - Workflow execution: <100ms overhead\n  - Latency: Sum of layers\n  - Reliability: 99%+ uptime\n\nLayer 3 (Llama):\n  - Token generation: 2-4 tok/s (70B on RTX 2060)\n  - Context retrieval: 50-200ms (Qdrant)\n  - Testing: 30-60s (cargo test)\n  - Total per task: 2-5 minutes\n```\n\n---\n\n## Scaling & Optimization\n\n### Phase 2: Fine-tune on Your Patterns\n\nAfter 50+ successful task completions:\n\n```bash\n# Collect (prompt, code_change) pairs\ncd ~/.perplexity/git-scrape-scripting\npython3 training/fine_tune_on_success.py \\\n  --successes tasks/completed \\\n  --output-dataset tasks/training_data.json\n\n# Fine-tune locally\npython3 training/model_trainer.py \\\n  --input tasks/training_data.json \\\n  --model-name llama2:70b \\\n  --epochs 5 \\\n  --learning-rate 1e-5\n```\n\n### Phase 3: Add Speculative Execution\n\nLlama proposes → Claude reviews in parallel → Merge if approved\n\n---\n\n## Troubleshooting\n\n**Claude returns empty response**\n- Check API key: `echo $PERPLEXITY_API_KEY`\n- Check rate limits: Monitor API dashboard\n- Increase timeout in n8n node\n\n**Llama returns incomplete code**\n- Increase max_tokens: `max_tokens=2048`\n- Adjust temperature: `temperature=0.5` (more deterministic)\n- Add more context: Fetch more similar commits\n\n**Tests failing after generation**\n- Check error message in n8n logs\n- Escalate to Claude: `--max-retries 3`\n- Review git-model context: Is it capturing patterns?\n\n---\n\n## Next Steps\n\n1. **This week**: Deploy n8n on Ryzen PC\n2. **Next week**: Integrate with Qdrant embeddings\n3. **Week 3**: Connect Claude API\n4. **Week 4**: Test end-to-end workflow\n5. **Month 2**: Fine-tune on successful completions\n6. **Month 3**: Add speculative execution and parallelization\n